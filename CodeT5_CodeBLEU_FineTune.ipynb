{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CodeT5_CodeBLEU_FineTune.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"836d8e93402e4b29a1b6748febfe2b82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c26144ea26945f7ac5df5b5c321628a","IPY_MODEL_11789467b2e5488f976aa0325d437b8a","IPY_MODEL_ddc951aa37b24140922713d63ae916ed"],"layout":"IPY_MODEL_4736c2a56d0c4c3896b83ded6f95ae34"}},"4c26144ea26945f7ac5df5b5c321628a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6282daef073842ddaebd7b8862e2d5c2","placeholder":"​","style":"IPY_MODEL_c19194f66a9f4db997d3cde6a5886281","value":"Sanity Checking DataLoader 0: 100%"}},"11789467b2e5488f976aa0325d437b8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_2703ff562fd14838ac1e1c5715d89bb3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41907aada9b14befaffd02d049bafdb1","value":1}},"ddc951aa37b24140922713d63ae916ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a459a0a7e5934899a6c9ac095fae4b36","placeholder":"​","style":"IPY_MODEL_de51bebe873d49c9b6255f7140cd7186","value":" 2/2 [00:00&lt;00:00,  2.01it/s]"}},"4736c2a56d0c4c3896b83ded6f95ae34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6282daef073842ddaebd7b8862e2d5c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c19194f66a9f4db997d3cde6a5886281":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2703ff562fd14838ac1e1c5715d89bb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41907aada9b14befaffd02d049bafdb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a459a0a7e5934899a6c9ac095fae4b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de51bebe873d49c9b6255f7140cd7186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"169785062bf9421abcae7457adbaf99c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5babc7f6a8b4469ba323670ef7732699","IPY_MODEL_ff1be5c848c348afaf57e50a0e6f9267","IPY_MODEL_822f50ed2b7d4ef4a2d911ccb5965717"],"layout":"IPY_MODEL_5b52c09abeb54905983dba4b4cb72b25"}},"5babc7f6a8b4469ba323670ef7732699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a47ebf9fd8420780beb56eb6059977","placeholder":"​","style":"IPY_MODEL_a03d8d178ddd43d7a5650d2e032f40bf","value":"Epoch 0: 100%"}},"ff1be5c848c348afaf57e50a0e6f9267":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a66bc78bc6314e48aad8a2ddcae77af8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdd4c599082c4c6aaf060891fbd48700","value":1}},"822f50ed2b7d4ef4a2d911ccb5965717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56903b4dd06c4dd491cf99fd4820bdc5","placeholder":"​","style":"IPY_MODEL_0af96582f8a24857a1fbee106d7ed7b6","value":" 34514/34514 [1:51:47&lt;00:00,  5.15it/s, loss=0.364, v_num=5]"}},"5b52c09abeb54905983dba4b4cb72b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"81a47ebf9fd8420780beb56eb6059977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a03d8d178ddd43d7a5650d2e032f40bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a66bc78bc6314e48aad8a2ddcae77af8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdd4c599082c4c6aaf060891fbd48700":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56903b4dd06c4dd491cf99fd4820bdc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0af96582f8a24857a1fbee106d7ed7b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d8df33b89f94758b817740fb20d1786":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6563684d4f87427b800299c3b5178f76","IPY_MODEL_977b028a694e467fbb3d760e23a1fe9b","IPY_MODEL_50a1f4ebc79844bca567935f0be04516"],"layout":"IPY_MODEL_8ebf5b1e4e65484592ab29f537d8d359"}},"6563684d4f87427b800299c3b5178f76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_005135d97d05441199e0021d8aa1ac0b","placeholder":"​","style":"IPY_MODEL_f3454774cf9b4b46b3a3172801363027","value":"Validation DataLoader 0: 100%"}},"977b028a694e467fbb3d760e23a1fe9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e3269dfa49843b89350290dcb363665","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0801a1b2241417d9e33b83caf4f0497","value":1}},"50a1f4ebc79844bca567935f0be04516":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7870ae33c5b487cb1ed309193b9406d","placeholder":"​","style":"IPY_MODEL_d0aa54273f384ac2a39a34112154332f","value":" 16366/16366 [26:04&lt;00:00, 10.46it/s]"}},"8ebf5b1e4e65484592ab29f537d8d359":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"005135d97d05441199e0021d8aa1ac0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3454774cf9b4b46b3a3172801363027":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e3269dfa49843b89350290dcb363665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0801a1b2241417d9e33b83caf4f0497":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7870ae33c5b487cb1ed309193b9406d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0aa54273f384ac2a39a34112154332f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gUtWDcnNNdR","executionInfo":{"status":"ok","timestamp":1650422575454,"user_tz":240,"elapsed":577,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"4748ab55-fba2-46ec-f043-b5232783541f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Apr 20 02:42:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    36W / 250W |   1149MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["## mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY_woW_JNV88","executionInfo":{"status":"ok","timestamp":1650461787358,"user_tz":240,"elapsed":13267,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"4d2ce631-c79c-475c-eea2-a66f6e7d9851"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9E8RxHIO3w7","executionInfo":{"status":"ok","timestamp":1650461790359,"user_tz":240,"elapsed":138,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"240c3f5b-f3e1-4a3a-f921-9e21a606c049"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmqVbmWkVjiT","executionInfo":{"status":"ok","timestamp":1650461623150,"user_tz":240,"elapsed":9856,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"07c1715b-2d29-42ba-8383-dc2a1d0c8742"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 50.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 36.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 36.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils import data\n","from transformers import RobertaTokenizer, T5ForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n","\n","class CodeContestDataset(data.Dataset):\n","    \"\"\"CodeContest dataset.\"\"\"\n","\n","    def __init__(self, csv_file, tokenizer):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file\n","        \"\"\"\n","        self.data = pd.read_csv(csv_file)\n","        self.data = self.data[(self.data[\"Solution Language\"] == \"PYTHON3\") & (self.data[\"Score\"].notnull())]\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.numpy()\n","\n","        score = float(self.data.iloc[idx, 6])\n","        score = '{0:.2f}'.format(score)\n","        code = None\n","        if pd.isnull(self.data.iloc[idx, 5]):\n","          code = self.data.iloc[idx, 4]\n","        else:\n","          code = self.data.iloc[idx, 5]\n","\n","        prefix_string = \"Score: \" + str(self.data.iloc[idx, 2])\n","        ids_object = self.tokenizer(prefix_string + \"</s>\" + str(code), return_tensors=\"pt\", padding='max_length')\n","        input_ids = ids_object.input_ids[0]\n","        attention_mask = ids_object.attention_mask[0]\n","\n","        output_ids_object = self.tokenizer(score, return_tensors=\"pt\")\n","        output_ids = output_ids_object.input_ids[0]\n","        output_attention_mask = output_ids_object.attention_mask[0]\n","\n","        sample = {\"source_ids\": input_ids, \"source_mask\": attention_mask, \"target_ids\": output_ids, \"target_mask\": output_attention_mask}\n","        return sample"],"metadata":{"id":"hApNDgO1PCEd","executionInfo":{"status":"ok","timestamp":1650461638002,"user_tz":240,"elapsed":11425,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["file_names = []\n","for filename in os.listdir(\"./DeepLearningFinalProject/CodeContestsClean\"):\n","  file_names.append(filename)\n","file_names.sort()"],"metadata":{"id":"KFNBS_vtASdr","executionInfo":{"status":"ok","timestamp":1650422591140,"user_tz":240,"elapsed":136,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["all_datasets = []\n","tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n","for filename in file_names:\n","  all_datasets.append(CodeContestDataset(\"./DeepLearningFinalProject/CodeContestsCleanCodeBLEU/\" + filename, tokenizer))\n","\n","all_data = data.ConcatDataset(all_datasets)\n","dataset = data.ConcatDataset(all_datasets[:150])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nadbth_CURh7","executionInfo":{"status":"ok","timestamp":1650422624109,"user_tz":240,"elapsed":31448,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"92ba55cb-eea4-4121-8a77-397388d1ff98"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DtypeWarning: Columns (1,2,3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n","  after removing the cwd from sys.path.\n"]}]},{"cell_type":"code","source":["len(all_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QT3S6wZswZD_","executionInfo":{"status":"ok","timestamp":1650422626890,"user_tz":240,"elapsed":164,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"d29709e9-9f6d-4505-b56f-33ea343ac920"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1045739"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6n7bjQeg20_J","executionInfo":{"status":"ok","timestamp":1650422628348,"user_tz":240,"elapsed":168,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"35510dcb-2c02-4f24-c1b4-8526d8ec8a13"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["783889"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["for i in range(5):\n","  sample = dataset[i]\n","  print(tokenizer.decode(sample[\"source_ids\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7C3_mu4BV4up","executionInfo":{"status":"ok","timestamp":1650398094275,"user_tz":240,"elapsed":163,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"228ee599-21be-4075-c847-4ee06457ac7a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<s>Score: One cold winter evening Alice and her older brother Bob was sitting at home near the fireplace and giving each other interesting problems to solve. When it was Alice's turn, she told the number n to Bob and said:\n","\n","—Shuffle the digits in this number in order to obtain the smallest possible number without leading zeroes.\n","\n","—No problem! — said Bob and immediately gave her an answer.\n","\n","Alice said a random number, so she doesn't know whether Bob's answer is correct. Help her to find this out, because impatient brother is waiting for the verdict.\n","\n","Input\n","\n","The first line contains one integer n (0 ≤ n ≤ 109) without leading zeroes. The second lines contains one integer m (0 ≤ m ≤ 109) — Bob's answer, possibly with leading zeroes.\n","\n","Output\n","\n","Print OK if Bob's answer is correct and WRONG_ANSWER otherwise.\n","\n","Examples\n","\n","Input\n","\n","3310\n","1033\n","\n","\n","Output\n","\n","OK\n","\n","\n","Input\n","\n","4\n","5\n","\n","\n","Output\n","\n","WRONG_ANSWER</s>def sort(s):\n","    return sorted(sorted(s), key=str.upper)\n","s=input()\n","s1=input()\n","l=sort(s)\n","c=l.count('0')\n","res=\"\"\n","if(len(l)>c):\n","    res=res+l[c]\n","for i in range(c):\n","    res=res+l[i]\n","for i in range(c+1,len(s)):\n","    res=res+l[i]\n","if(s1==res):\n","    print(\"OK\")\n","else:\n","    print(\"WRONG_ANSWER\")</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","<s>Score: One cold winter evening Alice and her older brother Bob was sitting at home near the fireplace and giving each other interesting problems to solve. When it was Alice's turn, she told the number n to Bob and said:\n","\n","—Shuffle the digits in this number in order to obtain the smallest possible number without leading zeroes.\n","\n","—No problem! — said Bob and immediately gave her an answer.\n","\n","Alice said a random number, so she doesn't know whether Bob's answer is correct. Help her to find this out, because impatient brother is waiting for the verdict.\n","\n","Input\n","\n","The first line contains one integer n (0 ≤ n ≤ 109) without leading zeroes. The second lines contains one integer m (0 ≤ m ≤ 109) — Bob's answer, possibly with leading zeroes.\n","\n","Output\n","\n","Print OK if Bob's answer is correct and WRONG_ANSWER otherwise.\n","\n","Examples\n","\n","Input\n","\n","3310\n","1033\n","\n","\n","Output\n","\n","OK\n","\n","\n","Input\n","\n","4\n","5\n","\n","\n","Output\n","\n","WRONG_ANSWER</s>n = int(input())\n","m = input()\n","v = []\n","zeros = 0\n","for c in str(n):\n","    if c!= '0':\n","        v.append(c)\n","    else:\n","        zeros += 1\n","v.sort()\n","res = (v[0] if len(v) > 0 else \"\") + ('0' * zeros)\n","for i in range(1, len(v)):\n","    res += v[i]\n","ans = \"WRONG_ANSWER\"\n","if m == res:\n","    ans = \"OK\"\n","print(ans)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","<s>Score: One cold winter evening Alice and her older brother Bob was sitting at home near the fireplace and giving each other interesting problems to solve. When it was Alice's turn, she told the number n to Bob and said:\n","\n","—Shuffle the digits in this number in order to obtain the smallest possible number without leading zeroes.\n","\n","—No problem! — said Bob and immediately gave her an answer.\n","\n","Alice said a random number, so she doesn't know whether Bob's answer is correct. Help her to find this out, because impatient brother is waiting for the verdict.\n","\n","Input\n","\n","The first line contains one integer n (0 ≤ n ≤ 109) without leading zeroes. The second lines contains one integer m (0 ≤ m ≤ 109) — Bob's answer, possibly with leading zeroes.\n","\n","Output\n","\n","Print OK if Bob's answer is correct and WRONG_ANSWER otherwise.\n","\n","Examples\n","\n","Input\n","\n","3310\n","1033\n","\n","\n","Output\n","\n","OK\n","\n","\n","Input\n","\n","4\n","5\n","\n","\n","Output\n","\n","WRONG_ANSWER</s>import sys\n","from array import array  # noqa: F401\n","\n","\n","def input():\n","    return sys.stdin.buffer.readline().decode('utf-8')\n","\n","\n","s, t = input().rstrip(), input().rstrip()\n","\n","if len(s) == 1:\n","    print('OK' if s == t else 'WRONG_ANSWER')\n","    exit()\n","\n","cnt = [0] * 10\n","for c in s:\n","    cnt[int(c)] += 1\n","\n","ans = ''\n","for i in range(len(s)):\n","    if i > 0 and cnt[0]:\n","        ans += '0'\n","        cnt[0] -= 1\n","    else:\n","        for j in range(1, 10):\n","            if cnt[j]:\n","                ans += str(j)\n","                cnt[j] -= 1\n","                break\n","\n","print('OK' if ans == t else 'WRONG_ANSWER')\n","</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","<s>Score: One cold winter evening Alice and her older brother Bob was sitting at home near the fireplace and giving each other interesting problems to solve. When it was Alice's turn, she told the number n to Bob and said:\n","\n","—Shuffle the digits in this number in order to obtain the smallest possible number without leading zeroes.\n","\n","—No problem! — said Bob and immediately gave her an answer.\n","\n","Alice said a random number, so she doesn't know whether Bob's answer is correct. Help her to find this out, because impatient brother is waiting for the verdict.\n","\n","Input\n","\n","The first line contains one integer n (0 ≤ n ≤ 109) without leading zeroes. The second lines contains one integer m (0 ≤ m ≤ 109) — Bob's answer, possibly with leading zeroes.\n","\n","Output\n","\n","Print OK if Bob's answer is correct and WRONG_ANSWER otherwise.\n","\n","Examples\n","\n","Input\n","\n","3310\n","1033\n","\n","\n","Output\n","\n","OK\n","\n","\n","Input\n","\n","4\n","5\n","\n","\n","Output\n","\n","WRONG_ANSWER</s>import sys\n","\n","first = sys.stdin.readline().strip()\n","second = sys.stdin.readline().strip()\n","\n","if first == '0' and second == '0':\n","    print(\"OK\")\n","    sys.exit(0)\n","\n","sortings = sorted(first)\n","\n","if sortings[0] == '0':\n","    for index in range(len(sortings)):\n","        if sortings[index]!= '0':\n","            sortings[0], sortings[index] = \\\n","              sortings[index], sortings[0]\n","            break\n","\n","if sortings[0] == '0':\n","    print(\"WRONG_ANSWER\")\n","    sys.exit(0)\n","\n","sorted_str = \"\"\n","\n","for i in sortings:\n","    sorted_str += i\n","\n","    #print(sorted_str)\n","\n","if sorted_str == second:\n","    print(\"OK\")\n","else:\n","    print(\"WRONG_ANSWER\")\n","</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","<s>Score: One cold winter evening Alice and her older brother Bob was sitting at home near the fireplace and giving each other interesting problems to solve. When it was Alice's turn, she told the number n to Bob and said:\n","\n","—Shuffle the digits in this number in order to obtain the smallest possible number without leading zeroes.\n","\n","—No problem! — said Bob and immediately gave her an answer.\n","\n","Alice said a random number, so she doesn't know whether Bob's answer is correct. Help her to find this out, because impatient brother is waiting for the verdict.\n","\n","Input\n","\n","The first line contains one integer n (0 ≤ n ≤ 109) without leading zeroes. The second lines contains one integer m (0 ≤ m ≤ 109) — Bob's answer, possibly with leading zeroes.\n","\n","Output\n","\n","Print OK if Bob's answer is correct and WRONG_ANSWER otherwise.\n","\n","Examples\n","\n","Input\n","\n","3310\n","1033\n","\n","\n","Output\n","\n","OK\n","\n","\n","Input\n","\n","4\n","5\n","\n","\n","Output\n","\n","WRONG_ANSWER</s>a = list(input())\n","b = input()\n","a.sort()\n","c = a.count('0')\n","d = 0\n","while d < c:\n","    a.remove(a[0])\n","    d += 1\n","if len(a) > 0:\n","    a[0] += ('0' * c)\n","else:\n","    a.append('0' * c)\n","e = ''.join(a)\n","if e == b:\n","    print('OK')\n","else:\n","    print('WRONG_ANSWER')\n","</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"]}]},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCA4H_OHZ8Jn","executionInfo":{"status":"ok","timestamp":1650461667174,"user_tz":240,"elapsed":9794,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"7be00921-527b-48fd-dd9f-a0224a8ff713"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n","\u001b[K     |████████████████████████████████| 582 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 62.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n","\u001b[K     |████████████████████████████████| 408 kB 57.5 MB/s \n","\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 48.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.8)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 56.3 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 61.0 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, pytorch-lightning\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 torchmetrics-0.8.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["import pytorch_lightning as pl\n","class T5FineTuner(pl.LightningModule):\n","  def __init__(self, hparams, train_dataset, model):\n","    super(T5FineTuner, self).__init__()\n","    self.hparams.update(vars(hparams))\n","    self.train_dataset = train_dataset\n","    self.model = model\n","    self.tokenizer = RobertaTokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n","  \n","  def is_logger(self):\n","    return True\n","  \n","  def forward(\n","      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n","  ):\n","    return self.model(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        decoder_input_ids=decoder_input_ids,\n","        decoder_attention_mask=decoder_attention_mask,\n","        labels=labels,\n","    )\n","\n","  def _step(self, batch):\n","    labels = batch[\"target_ids\"]\n","    labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","    outputs = self(\n","        input_ids=batch[\"source_ids\"],\n","        attention_mask=batch[\"source_mask\"],\n","        labels=labels,\n","        decoder_attention_mask=batch['target_mask']\n","    )\n","\n","    loss = outputs[0]\n","\n","    return loss\n","\n","  def training_step(self, batch, batch_idx):\n","    loss = self._step(batch)\n","\n","    tensorboard_logs = {\"train_loss\": loss}\n","    return {\"loss\": loss, \"log\": tensorboard_logs}\n","  \n","  def training_epoch_end(self, outputs):\n","    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n","    #tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n","    self.log(\"avg_train_loss\", avg_train_loss)\n","\n","  def validation_step(self, batch, batch_idx):\n","    loss = self._step(batch)\n","    return {\"val_loss\": loss}\n","  \n","  def validation_epoch_end(self, outputs):\n","    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n","    tensorboard_logs = {\"val_loss\": avg_loss}\n","    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n","\n","  def configure_optimizers(self):\n","    \"Prepare optimizer and schedule (linear warmup and decay)\"\n","\n","    model = self.model\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": self.hparams.weight_decay,\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n","    self.opt = optimizer\n","    return [optimizer]\n","  \n","  def optimizer_step(self,\n","                     epoch=None, \n","                    batch_idx=None, \n","                    optimizer=None, \n","                    optimizer_idx=None, \n","                    optimizer_closure=None, \n","                    on_tpu=None, \n","                    using_native_amp=None, \n","                    using_lbfgs=None\n","                     ):\n","\n","    optimizer.step(closure=optimizer_closure)\n","    optimizer.zero_grad()\n","    self.lr_scheduler.step()\n","  \n","  def get_tqdm_dict(self):\n","    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n","\n","    return tqdm_dict\n","\n","  def train_dataloader(self):\n","    dataloader = data.DataLoader(self.train_dataset, batch_size=self.hparams.train_batch_size, shuffle=True, num_workers=6, pin_memory=True)\n","    t_total = (\n","        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n","        // self.hparams.gradient_accumulation_steps\n","        * float(self.hparams.num_train_epochs)\n","    )\n","    scheduler = get_linear_schedule_with_warmup(\n","        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n","    )\n","    self.lr_scheduler = scheduler\n","    return dataloader\n","\n","  def val_dataloader(self):\n","    val_dataset = data.ConcatDataset(all_datasets[150:])\n","    return data.DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"],"metadata":{"id":"ZDqmWJKkWcsP","executionInfo":{"status":"ok","timestamp":1650461674130,"user_tz":240,"elapsed":1601,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import logging\n","logger = logging.getLogger(__name__)\n","\n","class LoggingCallback(pl.Callback):\n","  def on_validation_end(self, trainer, pl_module):\n","    logger.info(\"***** Validation results *****\")\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","      # Log results\n","      for key in sorted(metrics):\n","        if key not in [\"log\", \"progress_bar\"]:\n","          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","\n","  def on_test_end(self, trainer, pl_module):\n","    logger.info(\"***** Test results *****\")\n","\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","\n","      # Log and save results to file\n","      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n","      with open(output_test_results_file, \"w\") as writer:\n","        for key in sorted(metrics):\n","          if key not in [\"log\", \"progress_bar\"]:\n","            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"],"metadata":{"id":"GdFOOIO0biMF","executionInfo":{"status":"ok","timestamp":1650461679518,"user_tz":240,"elapsed":181,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["args_dict = dict(\n","    data_dir=\"\",\n","    output_dir=\"./DeepLearningFinalProject\",\n","    model_name_or_path='Salesforce/codet5-small',\n","    tokenizer_name_or_path='Salesforce/codet5-small',\n","    max_seq_length=512,\n","    learning_rate=1e-4,\n","    weight_decay=0.0,\n","    adam_epsilon=1e-8,\n","    warmup_steps=0,\n","    train_batch_size=16,\n","    eval_batch_size=16,\n","    num_train_epochs=1,\n","    gradient_accumulation_steps=8,\n","    n_gpu=1,\n","    fp_16=False,\n","    max_grad_norm=1.0,\n","    seed=42,\n",")"],"metadata":{"id":"z4tbxQnzb3PR","executionInfo":{"status":"ok","timestamp":1650461682575,"user_tz":240,"elapsed":148,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import argparse\n","args = argparse.Namespace(**args_dict)\n","\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    dirpath=args.output_dir, monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",")\n","\n","train_params = dict(\n","    accumulate_grad_batches=args.gradient_accumulation_steps,\n","    gpus=args.n_gpu,\n","    max_epochs=args.num_train_epochs,\n","    precision= 16 if args.fp_16 else 32,\n","    gradient_clip_val=args.max_grad_norm,\n","    checkpoint_callback=checkpoint_callback,\n","    callbacks=[LoggingCallback()],\n",")"],"metadata":{"id":"kr3ZODmcgfrq","executionInfo":{"status":"ok","timestamp":1650461686188,"user_tz":240,"elapsed":125,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#The below code is execute 3 times for 3 splits of the training data, due to system RAM constraints in Colab\n","model_base = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')\n","trainer = pl.Trainer(**train_params)\n","curr_dataset = data.ConcatDataset(all_datasets[100:150])\n","model = T5FineTuner(args, curr_dataset, model_base)\n","model.load_state_dict(torch.load(\"./DeepLearningFinalProject/model_codet5_small_codeBLEU_python3_04192022_split1.pt\"))\n","trainer.fit(model)\n","torch.save(model.state_dict(), \"./DeepLearningFinalProject/model_codet5_small_codeBLEU_python3_04192022_split2.pt\")"],"metadata":{"id":"IRlYsRJjhXRN","executionInfo":{"status":"ok","timestamp":1650418276822,"user_tz":240,"elapsed":6714458,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"colab":{"base_uri":"https://localhost:8080/","height":462,"referenced_widgets":["836d8e93402e4b29a1b6748febfe2b82","4c26144ea26945f7ac5df5b5c321628a","11789467b2e5488f976aa0325d437b8a","ddc951aa37b24140922713d63ae916ed","4736c2a56d0c4c3896b83ded6f95ae34","6282daef073842ddaebd7b8862e2d5c2","c19194f66a9f4db997d3cde6a5886281","2703ff562fd14838ac1e1c5715d89bb3","41907aada9b14befaffd02d049bafdb1","a459a0a7e5934899a6c9ac095fae4b36","de51bebe873d49c9b6255f7140cd7186","169785062bf9421abcae7457adbaf99c","5babc7f6a8b4469ba323670ef7732699","ff1be5c848c348afaf57e50a0e6f9267","822f50ed2b7d4ef4a2d911ccb5965717","5b52c09abeb54905983dba4b4cb72b25","81a47ebf9fd8420780beb56eb6059977","a03d8d178ddd43d7a5650d2e032f40bf","a66bc78bc6314e48aad8a2ddcae77af8","bdd4c599082c4c6aaf060891fbd48700","56903b4dd06c4dd491cf99fd4820bdc5","0af96582f8a24857a1fbee106d7ed7b6","2d8df33b89f94758b817740fb20d1786","6563684d4f87427b800299c3b5178f76","977b028a694e467fbb3d760e23a1fe9b","50a1f4ebc79844bca567935f0be04516","8ebf5b1e4e65484592ab29f537d8d359","005135d97d05441199e0021d8aa1ac0b","f3454774cf9b4b46b3a3172801363027","9e3269dfa49843b89350290dcb363665","f0801a1b2241417d9e33b83caf4f0497","a7870ae33c5b487cb1ed309193b9406d","d0aa54273f384ac2a39a34112154332f"]},"outputId":"7d126a2a-df9e-43de-cc95-3a7f03d41495"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f9f25b27bd0>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f9f25b27bd0>)`.\n","  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:118: UserWarning: When using `Trainer(accumulate_grad_batches != 1)` and overriding `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch (rather, they are called on every optimization step).\n","  \"When using `Trainer(accumulate_grad_batches != 1)` and overriding\"\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 60.5 M\n","-----------------------------------------------------\n","60.5 M    Trainable params\n","0         Non-trainable params\n","60.5 M    Total params\n","241.969   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"836d8e93402e4b29a1b6748febfe2b82"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"169785062bf9421abcae7457adbaf99c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d8df33b89f94758b817740fb20d1786"}},"metadata":{}}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eH_0Dv-ADg3d","executionInfo":{"status":"ok","timestamp":1650463862045,"user_tz":240,"elapsed":135,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"37f3cd31-870c-4cd6-bc4d-b44a4a16c239"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#The below code evaluates the mean absolute error on the validation data split\n","from sklearn import metrics\n","model.model.eval()\n","model.model.to(device)\n","test_dataset = data.ConcatDataset(all_datasets[150:])\n","loader = data.DataLoader(test_dataset, batch_size=16, num_workers=4)\n","actual = []\n","predicted = []\n","for batch_idx, batch in enumerate(loader):\n","  outs = model.model.generate(input_ids=batch['source_ids'].to(device), \n","                              attention_mask=batch['source_mask'].to(device), \n","                              max_length=6)\n","  dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n","  targets = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['target_ids']]\n","  actual.extend(targets)\n","  predicted.extend(dec)\n","\n","predicted = [float(x) for x in predicted]\n","actual = [float(x) for x in actual]\n","metrics.mean_absolute_error(actual, predicted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZw3nD_nYuwy","executionInfo":{"status":"ok","timestamp":1650426931518,"user_tz":240,"elapsed":3301085,"user":{"displayName":"Brendan Kondracki","userId":"14824001390510818675"}},"outputId":"4b6f0308-d863-470a-8dc6-c5b1c8426f51"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.16228726370059193"]},"metadata":{},"execution_count":53}]}]}